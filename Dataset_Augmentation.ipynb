{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "#import tiktoken\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Variables Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>newspaper_id</th>\n",
       "      <th>text_id</th>\n",
       "      <th>title</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>year</th>\n",
       "      <th>city</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PD1788</td>\n",
       "      <td>la-bomba-1895-01-13-page_1-1</td>\n",
       "      <td>La bomba</td>\n",
       "      <td>1</td>\n",
       "      <td>1894-1895</td>\n",
       "      <td>Rosario, Argentina</td>\n",
       "      <td>De antemano el triunfo estaba asegurado, porqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PF674</td>\n",
       "      <td>Image0048-page_0-0</td>\n",
       "      <td>El amolador</td>\n",
       "      <td>2</td>\n",
       "      <td>1878-1880</td>\n",
       "      <td>Bogotá</td>\n",
       "      <td>Ultimamente ha resultado que sobre ello nos da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PD1540</td>\n",
       "      <td>558a32a37d1ed64f16883d01-page_0-2</td>\n",
       "      <td>Patria festiva</td>\n",
       "      <td>0</td>\n",
       "      <td>1879</td>\n",
       "      <td>Ciudad de México</td>\n",
       "      <td>El gran viajero. Ha puesto a los de su partido...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PD1569</td>\n",
       "      <td>558a32cc7d1ed64f168b013a-page_0-0</td>\n",
       "      <td>El coyote</td>\n",
       "      <td>1</td>\n",
       "      <td>1880</td>\n",
       "      <td>Ciudad de México</td>\n",
       "      <td>Es preciso que los señores del gobierno invent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PD1087</td>\n",
       "      <td>86844de1-2628-5a12-aa7f-b796c6e62a4d_20-page_0-2</td>\n",
       "      <td>El murcielago</td>\n",
       "      <td>1</td>\n",
       "      <td>1856-1868</td>\n",
       "      <td>Lima, Perú</td>\n",
       "      <td>Lo creo ... Sí ... ) En esto acercose a ellos ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>PD1788</td>\n",
       "      <td>la-bomba-1894-04-29-page_2-2</td>\n",
       "      <td>La bomba</td>\n",
       "      <td>0</td>\n",
       "      <td>1894-1895</td>\n",
       "      <td>Rosario, Argentina</td>\n",
       "      <td>cabo vivímos en plena corrupcion administrativ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>PD1569</td>\n",
       "      <td>558a32ce7d1ed64f168b18fe-page_0-1</td>\n",
       "      <td>El coyote</td>\n",
       "      <td>2</td>\n",
       "      <td>1880</td>\n",
       "      <td>Ciudad de México</td>\n",
       "      <td>Vallarta .- Pues me quedo en In Corte para aqu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>PD1087</td>\n",
       "      <td>86844de1-2628-5a12-aa7f-b796c6e62a4d_08-page_0-3</td>\n",
       "      <td>El murcielago</td>\n",
       "      <td>1</td>\n",
       "      <td>1856-1868</td>\n",
       "      <td>Lima, Perú</td>\n",
       "      <td>Seis muchachos parió Lola, gordos, rollizos y ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>PD1087</td>\n",
       "      <td>86844de1-2628-5a12-aa7f-b796c6e62a4d_18-page_0-3</td>\n",
       "      <td>El murcielago</td>\n",
       "      <td>0</td>\n",
       "      <td>1856-1868</td>\n",
       "      <td>Lima, Perú</td>\n",
       "      <td>extraordinario es extraordinariamente, en un, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>PD761</td>\n",
       "      <td>p17054coll26_11634-page_3-2</td>\n",
       "      <td>El mago</td>\n",
       "      <td>0</td>\n",
       "      <td>1891-1898</td>\n",
       "      <td>Bogotá</td>\n",
       "      <td>NO ES FLOTA PRUEBENSE LOS SOMBREROS QUE FABRIC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     newspaper_id                                           text_id  \\\n",
       "0          PD1788                      la-bomba-1895-01-13-page_1-1   \n",
       "1           PF674                                Image0048-page_0-0   \n",
       "2          PD1540                 558a32a37d1ed64f16883d01-page_0-2   \n",
       "3          PD1569                 558a32cc7d1ed64f168b013a-page_0-0   \n",
       "4          PD1087  86844de1-2628-5a12-aa7f-b796c6e62a4d_20-page_0-2   \n",
       "...           ...                                               ...   \n",
       "4995       PD1788                      la-bomba-1894-04-29-page_2-2   \n",
       "4996       PD1569                 558a32ce7d1ed64f168b18fe-page_0-1   \n",
       "4997       PD1087  86844de1-2628-5a12-aa7f-b796c6e62a4d_08-page_0-3   \n",
       "4998       PD1087  86844de1-2628-5a12-aa7f-b796c6e62a4d_18-page_0-3   \n",
       "4999        PD761                       p17054coll26_11634-page_3-2   \n",
       "\n",
       "               title  chunk_id       year                city  \\\n",
       "0           La bomba         1  1894-1895  Rosario, Argentina   \n",
       "1        El amolador         2  1878-1880              Bogotá   \n",
       "2     Patria festiva         0       1879    Ciudad de México   \n",
       "3          El coyote         1       1880    Ciudad de México   \n",
       "4      El murcielago         1  1856-1868          Lima, Perú   \n",
       "...              ...       ...        ...                 ...   \n",
       "4995        La bomba         0  1894-1895  Rosario, Argentina   \n",
       "4996       El coyote         2       1880    Ciudad de México   \n",
       "4997   El murcielago         1  1856-1868          Lima, Perú   \n",
       "4998   El murcielago         0  1856-1868          Lima, Perú   \n",
       "4999         El mago         0  1891-1898              Bogotá   \n",
       "\n",
       "                                                   text  \n",
       "0     De antemano el triunfo estaba asegurado, porqu...  \n",
       "1     Ultimamente ha resultado que sobre ello nos da...  \n",
       "2     El gran viajero. Ha puesto a los de su partido...  \n",
       "3     Es preciso que los señores del gobierno invent...  \n",
       "4     Lo creo ... Sí ... ) En esto acercose a ellos ...  \n",
       "...                                                 ...  \n",
       "4995  cabo vivímos en plena corrupcion administrativ...  \n",
       "4996  Vallarta .- Pues me quedo en In Corte para aqu...  \n",
       "4997  Seis muchachos parió Lola, gordos, rollizos y ...  \n",
       "4998  extraordinario es extraordinariamente, en un, ...  \n",
       "4999  NO ES FLOTA PRUEBENSE LOS SOMBREROS QUE FABRIC...  \n",
       "\n",
       "[5000 rows x 7 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('EvaluationDatasets/5000_texts.csv', delimiter=',')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_price(model, in_tk, out_tk):\n",
    "    prices_per_1k = {\n",
    "        \"gpt-4o\": {\"input\": 0.0025, \"output\": 0.010},\n",
    "        \"gpt-4o-mini\": {\"input\": 0.00015, \"output\": 0.0006},\n",
    "    }\n",
    "\n",
    "    if model not in prices_per_1k:\n",
    "        raise ValueError(f\"Model {model} not found in the pricing list\")\n",
    "\n",
    "    input_cost = (in_tk / 1000) * prices_per_1k[model][\"input\"]\n",
    "    output_cost = (out_tk / 1000) * prices_per_1k[model][\"output\"]\n",
    "\n",
    "    return input_cost + output_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv('./.env')\n",
    "client = AzureOpenAI(\n",
    "\n",
    "    api_version=\"#####\",\n",
    "    azure_endpoint=\"#####\",\n",
    "    api_key=\"#####\"\n",
    ")\n",
    "engine = \"#####\"\n",
    "model = \"#####\"\n",
    "\n",
    "MAX_RETRIES = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request for Text Completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request(prompt, system_prompt=\"\", max_tokens=4096, temperature=0, try_count=0):\n",
    "    \"\"\"Request a completion from the OpenAI API.\n",
    "    :param prompt: The prompt to send to the API\n",
    "    :param max_tokens: The maximum number of tokens in the output\n",
    "    :param temperature: The degree of randomness in the output\n",
    "    :param try_count: Retry control parameter\n",
    "    :return response: The response from the API\n",
    "    :return usage: The count of token usage from the API { \"input\", \"output\" }\n",
    "    \"\"\"\n",
    "    #expected_tokens = count_tk(prompt)\n",
    "    #if expected_tokens > 4000:\n",
    "    #    return \"\", {\"input\": 0, \"output\": 0}, f\"length - INPUT too long ({expected_tokens} tokens)\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=engine,\n",
    "            max_tokens=max_tokens,\n",
    "            temperature=temperature,\n",
    "            messages=[{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        finish_reason = response.choices[0].finish_reason\n",
    "        if finish_reason == \"content_filter\":\n",
    "            rsp = \"\"\n",
    "            content_filter = response.choices[0].content_filter_results\n",
    "            prompt_filter = response.prompt_filter_results[0]['content_filter_results']\n",
    "            finish_reason += f\" - {get_filter_flags(content_filter, prompt_filter)}\"\n",
    "        else:\n",
    "            rsp = response.choices[0].message.content\n",
    "        return rsp, { \"input\": response.usage.prompt_tokens, \"output\": response.usage.completion_tokens }, finish_reason\n",
    "    except Exception as e:\n",
    "        response = \"\"\n",
    "        try: usage = { \"input\": response.usage.prompt_tokens, \"output\": response.usage.completion_tokens }\n",
    "        except: usage = { \"input\": 0, \"output\": 0 }\n",
    "        if \"content management policy\" in f\"{e}\":\n",
    "            finish_reason = \"content_filter - content_management_policy\"\n",
    "        else:\n",
    "            if \"Max retries exceeded with url\" in f\"{e}\":\n",
    "                if try_count >= MAX_RETRIES:\n",
    "                    return response, usage, f\"RETRYING, but reached MAX_RETRIES ({MAX_RETRIES})\"\n",
    "                print(f\"RETRYING ({try_count})...\")\n",
    "                time.sleep(60)\n",
    "                return request(prompt, max_tokens, temperature, try_count+1) # retry after 60 seconds\n",
    "            finish_reason = f\"ERROR [{type(e).__name__}]: {e}\"\n",
    "        return response, usage, finish_reason\n",
    "\n",
    "def get_filter_flags(content_filter, prompt_filter):\n",
    "    return ', '.join(\n",
    "        [f\"content.{k}\" for k, v in content_filter.items() if v != {'filtered': False, 'severity': 'safe'}] +\n",
    "        [f\"prompt.{k}\" for k, v in prompt_filter.items() if (k == 'jailbreak' and v != {'filtered': False, 'detected': False}) or (k != 'jailbreak' and v != {'filtered': False, 'severity': 'safe'})]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSES_FILE = \"EvaluationDatasets/responsesNewDataset.json\"\n",
    "\n",
    "r = {\"data\":[], \"checkpoint\": 0, \"input_tokens\": 0, \"output_tokens\": 0, \"fail_input_tokens\": 0, \"fail_output_tokens\": 0, \"total_price\": 0, \"price_per_req\": 0}\n",
    "if os.path.exists(RESPONSES_FILE):\n",
    "    with open(RESPONSES_FILE, \"r\") as f:\n",
    "        r = json.load(f)\n",
    "else:\n",
    "    with open(RESPONSES_FILE, \"w\") as f:\n",
    "        f.write(json.dumps(r, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done 1127/5000 (22.54%)\n"
     ]
    }
   ],
   "source": [
    "assert r['checkpoint'] == len(r['data']), \"Checkpoint does not match with executed requests\"\n",
    "print(f\"Done {r['checkpoint']}/{len(df)} ({100*r['checkpoint']/len(df):.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\\\n",
    "Se va a recibir un texto en español proveniente de la prensa latinoamamericana del siglo 19.\n",
    "Este texto puede o no contener alguna forma de ironía, es decir, cumple con una de las siguientes situaciones:\n",
    "- Presenta una contradicción entre la realidad descrita en el contexto y lo que se dice.\n",
    "- Presenta una contradicción entre la realidad histórica del siglo 19 en Latinoamérica con lo que se dice\n",
    "- Presenta una contradicción entre lo que se dice y el tono de como se dice (basándose en el uso de mayúsculas y signos de puntuación).\n",
    "\n",
    "Este texto puede contener una crítica a una situación política o social contradictoria que sucedía, pero no necesariamente es una ironía, sino una opinión política negativa. \n",
    "El texto también puede contener comparaciones contradictorias o hipérboles, pero no necesariamente es una ironía, sino una expresión con lenguaje poético. Para que sea una contradicción irónica debe existir una intención de comicidad o burla en el texto, no únicamente una intención de crítica o contradicción política o una intención de descripción figurativa o poética. \n",
    "\n",
    "La tarea a realizar es la identificar si existe ironía o no, presente en alguna contradicción en el texto y explicar el porqué es contradictoria y cuál es la intención del autor del texto. En caso de que no exista una ironía detectada, se debe explicar el porqué no es ironía e indicar si es un texto con un sentimiento positivo, negativo o neutro. \n",
    "La respuesta debe comenzar con una de estas 4 palabras de acuerdo con lo inferido: “IRONÍA”, “POSITIVO”, “NEGATIVO” “NEUTRO”, escrito entre comillas sencillas (''). A continuación se debe añadir entre asteriscos (*) la explicación de cuál es la contradicción en caso de que sea ironía, o por qué no es ironía. \n",
    "No debes incluir nada más allá de lo que se está solicitando. La respuesta final no debe contener más de 500 palabras en total, incluyendo la descripción.\\\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in df.loc[r['checkpoint']:, \"text\"]:\n",
    "    prompt = text\n",
    "    #print(f\"------------------------------- {r['checkpoint']+1} -----------------------------------\")\n",
    "    #print(prompt)\n",
    "    response, usage, finish_reason = request(prompt, system_prompt)\n",
    "    #print(response if response else f\"ERROR: {finish_reason}\")\n",
    "    if finish_reason in ['stop', 'length']:\n",
    "        r[\"input_tokens\"] += usage[\"input\"]\n",
    "        r[\"output_tokens\"] += usage[\"output\"]\n",
    "    else:\n",
    "        r[\"fail_input_tokens\"] += usage[\"input\"]\n",
    "        r[\"fail_output_tokens\"] += usage[\"output\"]\n",
    "\n",
    "    r[\"data\"].append({\n",
    "        \"text\": text,\n",
    "        \"resp\": response,\n",
    "        \"finish_reason\": finish_reason\n",
    "    })\n",
    "\n",
    "    r[\"checkpoint\"] += 1\n",
    "\n",
    "    if r['checkpoint'] % 10 == 0:\n",
    "        price = compute_price(model, r['input_tokens']+r[\"fail_input_tokens\"], r['output_tokens']+r[\"fail_output_tokens\"])\n",
    "        r['total_price'] = round(price, 4)\n",
    "        r['price_per_req'] = round(price / r['checkpoint'], 6)\n",
    "        with open(RESPONSES_FILE, \"w\") as f:\n",
    "            f.write(json.dumps(r, indent=4))\n",
    "        print(f\"SAVED ({r['checkpoint']})\")\n",
    "\n",
    "with open(RESPONSES_FILE, \"w\") as f:\n",
    "    f.write(json.dumps(r, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRONÍA: Count = 770, Percentage = 73.68%\n",
      "NEUTRO: Count = 235, Percentage = 22.49%\n",
      "NEGATIVO: Count = 40, Percentage = 3.83%\n",
      "Total: 1045 (quitando las que fallaron por el filtro de contenido)\n"
     ]
    }
   ],
   "source": [
    "clsf = []\n",
    "for s in r['data']:\n",
    "    rsp = s['resp']\n",
    "    if s['finish_reason'] == \"stop\":\n",
    "        match = re.search(r\"'(.*?)'\", rsp)\n",
    "        if match:\n",
    "            extracted_word = match.group(1)\n",
    "            clsf.append(extracted_word)\n",
    "\n",
    "class_counts = Counter(clsf)\n",
    "total_classes = len(clsf)\n",
    "class_percentages = {cls: (count / total_classes) * 100 for cls, count in class_counts.items()}\n",
    "\n",
    "for cls, count in class_counts.items():\n",
    "    print(f\"{cls}: Count = {count}, Percentage = {class_percentages[cls]:.2f}%\")\n",
    "    \n",
    "print(f\"Total: {len(clsf)} (quitando las que fallaron por el filtro de contenido)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
